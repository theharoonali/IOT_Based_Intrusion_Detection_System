{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "with open('knn_model.pkl', 'rb') as file:\n",
    "    knn_model = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#newdataframe\n",
    "new_df = pd.read_csv('predict_attack.csv')\n",
    "\n",
    "# Extract the feature columns from the new DataFrame and convert to numpy array\n",
    "X_new = new_df[['Src_Port',\n",
    " 'Dst_Port',\n",
    " 'Protocol',\n",
    " 'Flow_Duration',\n",
    " 'Tot_Fwd_Pkts',\n",
    " 'Tot_Bwd_Pkts',\n",
    " 'TotLen_Fwd_Pkts',\n",
    " 'TotLen_Bwd_Pkts',\n",
    " 'Fwd_Pkt_Len_Max',\n",
    " 'Fwd_Pkt_Len_Min',\n",
    " 'Fwd_Pkt_Len_Mean',\n",
    " 'Fwd_Pkt_Len_Std',\n",
    " 'Bwd_Pkt_Len_Max',\n",
    " 'Bwd_Pkt_Len_Min',\n",
    " 'Bwd_Pkt_Len_Mean',\n",
    " 'Bwd_Pkt_Len_Std',\n",
    " 'Flow_IAT_Mean',\n",
    " 'Flow_IAT_Std',\n",
    " 'Flow_IAT_Max',\n",
    " 'Flow_IAT_Min',\n",
    " 'Fwd_IAT_Tot',\n",
    " 'Fwd_IAT_Mean',\n",
    " 'Fwd_IAT_Std',\n",
    " 'Fwd_IAT_Max',\n",
    " 'Fwd_IAT_Min',\n",
    " 'Bwd_IAT_Tot',\n",
    " 'Bwd_IAT_Mean',\n",
    " 'Bwd_IAT_Std',\n",
    " 'Bwd_IAT_Max',\n",
    " 'Bwd_IAT_Min',\n",
    " 'Fwd_PSH_Flags',\n",
    " 'Bwd_PSH_Flags',\n",
    " 'Fwd_URG_Flags',\n",
    " 'Bwd_URG_Flags',\n",
    " 'Fwd_Header_Len',\n",
    " 'Bwd_Header_Len',\n",
    " 'Fwd_Pkts/s',\n",
    " 'Bwd_Pkts/s',\n",
    " 'Pkt_Len_Min',\n",
    " 'Pkt_Len_Max',\n",
    " 'Pkt_Len_Mean',\n",
    " 'Pkt_Len_Std',\n",
    " 'Pkt_Len_Var',\n",
    " 'FIN_Flag_Cnt',\n",
    " 'SYN_Flag_Cnt',\n",
    " 'RST_Flag_Cnt',\n",
    " 'PSH_Flag_Cnt',\n",
    " 'ACK_Flag_Cnt',\n",
    " 'URG_Flag_Cnt',\n",
    " 'CWE_Flag_Count',\n",
    " 'ECE_Flag_Cnt',\n",
    " 'Down/Up_Ratio',\n",
    " 'Pkt_Size_Avg',\n",
    " 'Fwd_Seg_Size_Avg',\n",
    " 'Bwd_Seg_Size_Avg',\n",
    " 'Fwd_Byts/b_Avg',\n",
    " 'Fwd_Pkts/b_Avg',\n",
    " 'Fwd_Blk_Rate_Avg',\n",
    " 'Bwd_Byts/b_Avg',\n",
    " 'Bwd_Pkts/b_Avg',\n",
    " 'Bwd_Blk_Rate_Avg',\n",
    " 'Subflow_Fwd_Pkts',\n",
    " 'Subflow_Fwd_Byts',\n",
    " 'Subflow_Bwd_Pkts',\n",
    " 'Subflow_Bwd_Byts',\n",
    " 'Init_Fwd_Win_Byts',\n",
    " 'Init_Bwd_Win_Byts',\n",
    " 'Fwd_Act_Data_Pkts',\n",
    " 'Fwd_Seg_Size_Min',\n",
    " 'Active_Mean',\n",
    " 'Active_Std',\n",
    " 'Active_Max',\n",
    " 'Active_Min',\n",
    " 'Idle_Mean',\n",
    " 'Idle_Std',\n",
    " 'Idle_Max',\n",
    " 'Idle_Min',\n",
    " 'S_octet1',\n",
    " 'S_octet2',\n",
    " 'S_octet3',\n",
    " 'S_octet4',\n",
    " 'D_octet1',\n",
    " 'D_octet2',\n",
    " 'D_octet3',\n",
    " 'D_octet4']].values\n",
    "\n",
    "new_predictions = knn_model.predict(X_new)\n",
    "\n",
    "# Add the predicted output features to the new DataFrame\n",
    "new_df['output_Label'] = new_predictions[:, 0]\n",
    "new_df['output_Cat'] = new_predictions[:, 1]\n",
    "\n",
    "# Write the new DataFrame with predicted output features to a new CSV file\n",
    "new_df.to_csv('results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Id               Timestamp           Dst_IP           Src_IP output_Label   \n",
      "0    0  25/07/2019 03:25:53 AM     192.168.0.16     192.168.0.13      Anomaly  \\\n",
      "1    1  26/05/2019 10:11:06 PM     192.168.0.13  222.160.179.132      Anomaly   \n",
      "2    2  11/07/2019 01:24:48 AM     192.168.0.13     192.168.0.16      Anomaly   \n",
      "3    3  04/09/2019 03:58:17 AM     192.168.0.13     192.168.0.16      Anomaly   \n",
      "4    4  10/09/2019 01:41:18 AM  239.255.255.250      192.168.0.1      Anomaly   \n",
      "5    5  10/09/2019 01:39:13 AM   101.79.244.148     192.168.0.24      Anomaly   \n",
      "6    6  25/07/2019 03:21:01 AM    210.89.164.90     192.168.0.24      Anomaly   \n",
      "7    7  11/07/2019 01:52:37 AM     58.225.75.83     192.168.0.24      Anomaly   \n",
      "8    8  25/07/2019 03:21:13 AM    210.89.164.90     192.168.0.13      Anomaly   \n",
      "9    9  26/05/2019 10:20:36 PM     192.168.0.13  111.149.163.151      Anomaly   \n",
      "10  10  04/09/2019 03:58:32 AM     40.100.49.34     192.168.0.24      Anomaly   \n",
      "11  11  25/07/2019 03:26:18 AM     192.168.0.24  104.118.134.215      Anomaly   \n",
      "12  12  25/07/2019 03:24:59 AM     52.219.36.20     192.168.0.13      Anomaly   \n",
      "13  13  25/07/2019 03:25:48 AM     192.168.0.16     192.168.0.13      Anomaly   \n",
      "14  14  25/07/2019 03:20:43 AM    210.89.164.90     192.168.0.24      Anomaly   \n",
      "15  16  25/07/2019 03:24:09 AM     192.168.0.16     192.168.0.13      Anomaly   \n",
      "16  18  25/07/2019 03:24:23 AM     192.168.0.16     192.168.0.13      Anomaly   \n",
      "17  19  25/07/2019 03:21:07 AM    210.89.164.90     192.168.0.24      Anomaly   \n",
      "18  20  25/07/2019 03:25:42 AM     192.168.0.16     192.168.0.13      Anomaly   \n",
      "\n",
      "   output_Cat  \n",
      "0       Mirai  \n",
      "1         DoS  \n",
      "2        Scan  \n",
      "3        Scan  \n",
      "4       Mirai  \n",
      "5       Mirai  \n",
      "6       Mirai  \n",
      "7       Mirai  \n",
      "8       Mirai  \n",
      "9         DoS  \n",
      "10      Mirai  \n",
      "11      Mirai  \n",
      "12      Mirai  \n",
      "13      Mirai  \n",
      "14      Mirai  \n",
      "15      Mirai  \n",
      "16      Mirai  \n",
      "17      Mirai  \n",
      "18      Mirai  \n"
     ]
    }
   ],
   "source": [
    "import smtplib\n",
    "\n",
    "# read the csv file\n",
    "new_df3 = pd.read_csv('results.csv')\n",
    "\n",
    "# count the number of anomalies\n",
    "num_anomalies = new_df3['output_Label'].str.contains('Anomaly').sum()\n",
    "\n",
    "# calculate the percentage of anomalies\n",
    "anomaly_pct = num_anomalies / len(new_df3)\n",
    "\n",
    "sender = \"xosepo2109@meidecn.com\"\n",
    "receiver = \"alerttheuser@gmail.com\"\n",
    "\n",
    "message = f\"\"\"\\\n",
    "Subject: Anomaly Detected!\n",
    "To: {receiver}\n",
    "From: {sender}\n",
    "\n",
    "IDS has detected {num_anomalies} Anomalies, Urgent visit the dashboard at http://10.122.168.123:5000\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "2023 The IDS, All Rights Reserved.\n",
    "\"\"\"\n",
    "\n",
    "# if the percentage is greater than 1%, show the anomalies\n",
    "if anomaly_pct > 0.01:\n",
    "    # read the csv file\n",
    "    new_df2 = pd.read_csv('results.csv')\n",
    "\n",
    "    # filter the rows where output_Label contains 'anomaly'\n",
    "    filtered_df = new_df2[new_df2['output_Label'].str.contains('Anomaly')]\n",
    "\n",
    "    # select only the required columns\n",
    "    filtered_df = filtered_df[['Id','Timestamp','Dst_IP', 'Src_IP', 'output_Label', 'output_Cat']]\n",
    "\n",
    "    # Write the new DataFrame\n",
    "    filtered_df.to_csv('results.csv', index=False)\n",
    "\n",
    "    #playsound.playsound('alert.wav', True)\n",
    "    #time.sleep(5)\n",
    "\n",
    "\n",
    "    \n",
    "    with smtplib.SMTP(\"sandbox.smtp.mailtrap.io\", 2525) as server:\n",
    "        server.login(\"\", \"\")\n",
    "        server.sendmail(sender, receiver, message)\n",
    "    # print the filtered dataframe\n",
    "    print(filtered_df)\n",
    "else:\n",
    "\n",
    "    # print the filtered dataframe\n",
    "    print(\"No Anomalies Detected!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
